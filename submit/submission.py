
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄁͏󠄄͏󠄀
#################################################
# file to edit: notebook.ipynb͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄁͏󠄄͏󠄀

import numpy as np
import operator

def part_1_a():
    """Provide probabilities for the word HMMs outlined below.
    Word ALLIGATOR, NUTS, and SLEEP.
    Review Udacity Lesson 8 - Video #29. HMM Training
    Returns:
        tuple() of
        (prior probabilities for all states for word ALLIGATOR,
         transition probabilities between states for word ALLIGATOR,
         emission parameters tuple(mean, std) for all states for word ALLIGATOR,
         prior probabilities for all states for word NUTS,
         transition probabilities between states for word NUTS,
         emission parameters tuple(mean, std) for all states for word NUTS,
         prior probabilities for all states for word SLEEP,
         transition probabilities between states for word SLEEP,
         emission parameters tuple(mean, std) for all states for word SLEEP)
        Sample Format (not complete):
        (
            {'A1': prob_of_starting_in_A1, 'A2': prob_of_starting_in_A2, ...},
            {'A1': {'A1': prob_of_transition_from_A1_to_A1,
                    'A2': prob_of_transition_from_A1_to_A2,
                    'A3': prob_of_transition_from_A1_to_A3,
                    'Aend': prob_of_transition_from_A1_to_Aend},
             'A2': {...}, ...},
            {'A1': tuple(mean_of_A1, standard_deviation_of_A1),
             'A2': tuple(mean_of_A2, standard_deviation_of_A2), ...},
            {'N1': prob_of_starting_in_N1, 'N2': prob_of_starting_in_N2, ...},
            {'N1': {'N1': prob_of_transition_from_N1_to_N1,
                    'N2': prob_of_transition_from_N1_to_N2,
                    'N3': prob_of_transition_from_N1_to_N3,
                    'Nend': prob_of_transition_from_N1_to_Nend},
             'N2': {...}, ...}
            {'N1': tuple(mean_of_N1, standard_deviation_of_N1),
             'N2': tuple(mean_of_N2, standard_deviation_of_N2), ...},
            {'S1': prob_of_starting_in_S1, 'S2': prob_of_starting_in_S2, ...},
            {'S1': {'S1': prob_of_transition_from_S1_to_S1,
                    'S2': prob_of_transition_from_S1_to_S2,
                    'S3': prob_of_transition_from_S1_to_S3,
                    'Send': prob_of_transition_from_S1_to_Send},
             'S2': {...}, ...}
            {'S1': tuple(mean_of_S1, standard_deviation_of_S1),
             'S2': tuple(mean_of_S2, standard_deviation_of_S2), ...}
        )
    """

    # TODO: complete this function.͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄁͏󠄄͏󠄀

    """Word ALLIGATOR"""
    a_prior_probs = {
        'A1': .333,
        'A2': 0,
        'A3':0,
        'Aend': 0
    }
    a_transition_probs = {
        'A1': {'A1': .833, 'A3': 0., 'A2': .167, 'Aend': 0.},
        'A2': {'A1': 0., 'A2': .786, 'A3': .214, 'Aend': 0.},
        'A3': {'A2': 0., 'A3': .727, 'A1': 0., 'Aend': .273},
        'Aend': {'A1': 0., 'A3': 0., 'A2': 0., 'Aend': 1}
    }
    # Parameters for end state is not required͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄁͏󠄄͏󠄀
    a_emission_paras = {
        'A1': (51.056, 21.986),
        'A2': (28.357, 14.936),
        'A3': (53.727, 16.707),
        'Aend': (None, None)
    }

    """Word NUTS"""
    n_prior_probs = {
        'N1': .333,
        'N2': 0.,
        'N3': 0.0,
        'Nend': 0
    }
    # Probability of a state changing to another state.͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄁͏󠄄͏󠄀
    n_transition_probs = {
        'N1': {'N3': 0, 'N1': .919, 'N2': .081, 'Nend': 0.},
        'N2': {'N3': 1, 'N1': 0, 'N2': 0., 'Nend': 0.},
        'N3': {'N3': .625, 'N1': 0., 'N2': 0., 'Nend': .375},
        'Nend': {'N3': 0., 'N2': 0., 'N1': 0., 'Nend': 1}
    }
    # Parameters for end state is not required͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄁͏󠄄͏󠄀
    n_emission_paras = {
        'N1': (38.081, 11.175),
        'N2': (42, 2.828),
        'N3': (60, 13.491),
        'Nend': (None, None)
    }

    """Word SLEEP"""
    s_prior_probs = {
        'S1': .333,
        'S2': 0.,
        'S3': 0.,
        'Send': 0.
    }
    s_transition_probs = {
        'S1': {'S2': .375, 'S3': 0., 'S1': .625, 'Send': 0.},
        'S2': {'S1': 0., 'S2': .864, 'S3': .136, 'Send': 0.},
        'S3': {'S2': 0., 'S1': 0., 'S3': 0, 'Send': 1},
        'Send': {'S2': 0., 'S3': 0., 'S1': 0., 'Send': 1}
    }
    # Parameters for end state is not required͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄁͏󠄄͏󠄀
    s_emission_paras = {
        'S1': (29.5, 8.411),
        'S2': (36.182, 5.99),
        'S3': (36.667, 1.886),
        'Send': (None, None)
    }

    return (a_prior_probs, a_transition_probs, a_emission_paras,
            n_prior_probs, n_transition_probs, n_emission_paras,
            s_prior_probs, s_transition_probs, s_emission_paras)

########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄁͏󠄄͏󠄀
##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄁͏󠄄͏󠄀
################ END OF LOCAL TEST CODE SECTION ######################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄁͏󠄄͏󠄀

def gaussian_prob(x, para_tuple):
    """Compute the probability of a given x value

    Args:
        x (float): observation value
        para_tuple (tuple): contains two elements, (mean, standard deviation)

    Return:
        Probability of seeing a value "x" in a Gaussian distribution.

    Note:
        We simplify the problem so you don't have to take care of integrals.
        Theoretically speaking, the returned value is not a probability of x,
        since the probability of any single value x from a continuous
        distribution should be zero, instead of the number outputted here.
        By definition, the Gaussian percentile of a given value "x"
        is computed based on the "area" under the curve, from left-most to x.
        The probability of getting value "x" is zero because a single value "x"
        has zero width, however, the probability of a range of value can be
        computed, for say, from "x - 0.1" to "x + 0.1".

    """
    if list(para_tuple) == [None, None]:
        return 0.0

    mean, std = para_tuple
    gaussian_percentile = (2 * np.pi * std**2)**-0.5 * \
                          np.exp(-(x - mean)**2 / (2 * std**2))
    return gaussian_percentile



def viterbi(evidence_vector, states, prior_probs,
            transition_probs, emission_paras):
    """Viterbi Algorithm to calculate the most likely states give the evidence.
    Args:
        evidence_vector (list): List of right hand Y-axis positions (integer).
        states (list): List of all states in a word. No transition between words.
                       example: ['A1', 'A2', 'A3', 'Aend', 'N1', 'N2', 'N3', 'Nend']
        prior_probs (dict): prior distribution for each state.
                            example: {'X1': 0.25,
                                      'X2': 0.25,
                                      'X3': 0.25,
                                      'Xend': 0.25}
        transition_probs (dict): dictionary representing transitions from each
                                 state to every other valid state such as for the above
                                 states, there won't be a transition from 'A1' to 'N1'
        emission_paras (dict): parameters of Gaussian distribution
                                from each state.
    Return:
        tuple of
        ( A list of states the most likely explains the evidence,
          probability this state sequence fits the evidence as a float )
    Note:
        You are required to use the function gaussian_prob to compute the
        emission probabilities.
    """

    # TODO: complete this function.͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄁͏󠄄͏󠄀
    # make the trellis of size states x timesteps
        # initialize
    if len(evidence_vector) == 0:
        return None, 0.0
    vib = np.zeros((len(states), len(evidence_vector)))
    # path store - store paths that have max probability
        # pointy contains indexes of the state in states that has max prob of
        # transitioning to currState at t
    pointy = np.zeros((len(states), len(evidence_vector)))
    #print(len(evidence_vector))
    # fill in prior probz first in the first column
    for u, p in enumerate(states) :
        vib[u, 0] = prior_probs[p] * gaussian_prob(evidence_vector[0], emission_paras[p])
    # fill in the rest that aren't prior probs
    # for each time step
    for t in range(1, len(evidence_vector)) :
        # for each state get the probability at the time t
        # iterate through all states before going to next time step
        for s, stat in enumerate(states) :
            # keep track of highest probability for each state in each time step
            highProb = 0
            # iterate through all of the states to get the probabilities and find the highest
            for n, newState in enumerate(states):
                #print(newState)
                # get the previous highest probability
                oldP = vib[n, t-1]
                # transition probability between states
                if newState[0] == stat[0] :
                    tranP = transition_probs[newState][stat]
                else :
                    tranP = 0
                #tranP = transition_probs[states[newState]][states[s]]
                # emission probability at t at the new state
                emitP = gaussian_prob(evidence_vector[t], emission_paras[states[s]])
                # get total prob
                totProb = tranP * emitP * oldP
                # if the current probability is higher than before
                if totProb > highProb :
                    # replace it
                    highProb = totProb
                    # put it in the tracer thingy
                    #pointy[s, t] = newState
                    pointy[s, t] = n
            # put the highest probabiltiy one in there of all
            vib[s, t] = highProb
    # now that all the max values for each are put in
    # follow pointy back from the highest probability
    maxy = np.argmax(vib[:, -1])
    # find the state of the max from the indices found in maxy
    seq = [states[maxy]]
    # set current state to the last one
    currState = seq[-1]
    # highest probability one is the one we return
    prob = vib[maxy , -1]
    # go backwards and start tracing
    for e in range((len(evidence_vector)-1), 0, -1) :
        # previous index is the one after
        prevInd = pointy[states.index(currState), e]
        prevState = states[int(prevInd)]
        seq.append(prevState)
        # go backwards
        currState = prevState
    #print(seq[::-1])
    #print(prob)
    return (seq[::-1], np.max(prob))
    # probabilities for prior states
    # start at S1
    # multiply each value by the transition probability for each one
    # for each time frame, multiply the transition probability and the output probability
        # the highest value is the highest chance path
        # find the max of each row
    # look at output distribution to see how probable the given value is in each state for each time step
        # for each time step, then for each state in each time step
    # get the most likely path


########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄁͏󠄄͏󠄀
##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄁͏󠄄͏󠄀
################ END OF LOCAL TEST CODE SECTION ######################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄁͏󠄄͏󠄀

def part_2_a():
    """Provide probabilities for the word HMMs outlined below.
    Now, at each time frame you are given 2 observations (right hand Y
    position & right thumb Y position). Use the result you derived in
    part_1_a, accompany with the provided probability for right thumb, create
    a tuple of (right-hand-y, right-thumb-y) to represent high-dimension transition &
    emission probabilities.
    """

     # TODO: complete this function.͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄁͏󠄄͏󠄀
    #raise NotImplementedError()

    """Word ALLIGATOR"""
    a_prior_probs = {
        'A1': 0.333,
        'A2': 0.,
        'A3': 0.,
        'Aend': 0.
    }
    # example: {'A1': {'A1' : (right-hand Y, right-thumb Y), ... }͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄁͏󠄄͏󠄀
    a_transition_probs = {
        'A1': {'A2': (0.167, 0.176), 'A1': (0.833, 0.824), 'A3': (0., 0.), 'Aend': (0., 0.)},
        'A2': {'A3': (0.214, 0.231), 'A2': (0.786, 0.769), 'A1': (0., 0.), 'Aend': (0., 0.)},
        'A3': {'A2': (0., 0.), 'A3': (0.727, .769), 'A1': (0., 0.), 'Aend': (0.273, .231)},
        'Aend': {'A2': (0., 0.), 'A1': (0., 0.), 'A3': (0., 0.), 'Aend': (1, 1)}
    }
    # example: {'A1': [(right-hand-mean, right-thumb-std), (right-hand--mean, right-thumb-std)] ...}͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄁͏󠄄͏󠄀
    a_emission_paras = {
        'A1': [(51.056, 21.986), (53.529, 17.493)],
        'A2': [(28.357, 14.936), (40.769, 6.104)],
        'A3': [(53.727, 16.707), (51, 12.316)],
        'Aend': [(None, None), (None, None)]
    }

    """Word NUTS"""
    n_prior_probs = {
        'N1': 0.333,
        'N2': 0.,
        'N3': 0.,
        'Nend': 0.
    }
    n_transition_probs = {
        'N1': {'N2': (0.081, 0.136), 'N1': (0.919, 0.864), 'N3': (0., 0.), 'Nend': (0., 0.)},
        'N2': {'N3': (1., 0.273), 'N1': (0., 0.), 'N2': (0., 0.727), 'Nend': (0., 0.)},
        'N3': {'N1': (0., 0.), 'N3': (0.625, 0.8), 'N2': (0., 0.), 'Nend': (0.375, 0.2)},
        'Nend': {'N1': (0., 0.), 'N2': (0., 0.), 'N3': (0., 0.), 'Nend': (1., 1.)}
    }
    n_emission_paras = {
        'N1': [(38.081, 11.175), (36.318, 7.376)],
        'N2': [(42, 2.828), (60, 15.829)],
        'N3': [(60, 13.491), (37.476, 8.245)],
        'Nend': [(None, None), (None, None)]
    }

    """Word SLEEP"""
    s_prior_probs = {
        'S1': 0.333,
        'S2': 0.,
        'S3': 0.,
        'Send': 0.
    }
    s_transition_probs = {
        'S1': {'S2': (0.375, 0.214), 'S3': (0., 0.), 'S1': (0.625, 0.786), 'Send': (0., 0.)},
        'S2': {'S1': (0., 0.), 'S3': (0.136, 0.231), 'S2': (0.864, 0.769), 'Send': (0., 0.)},
        'S3': {'S3': (0., 0.5), 'S1': (0., 0.), 'S2': (0., 0.), 'Send': (1., 0.5)},
        'Send': {'S3': (0., 0.), 'S1': (0., 0.), 'S2': (0., 0.), 'Send': (1., 1.)}
    }
    s_emission_paras = {
        'S1': [(29.5, 8.411), (35.357, 7.315)],
        'S2': [(36.182, 5.99), (31.462, 5.048)],
        'S3': [(36.667, 1.886), (38.333, 7.409)],
        'Send': [(None, None), (None, None)]
    }

    return (a_prior_probs, a_transition_probs, a_emission_paras,
            n_prior_probs, n_transition_probs, n_emission_paras,
            s_prior_probs, s_transition_probs, s_emission_paras)

########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄁͏󠄄͏󠄀
##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄁͏󠄄͏󠄀
################ END OF LOCAL TEST CODE SECTION ######################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄁͏󠄄͏󠄀

def multidimensional_viterbi(evidence_vector, states, prior_probs,
                             transition_probs, emission_paras):
    """Decode the most likely word phrases generated by the evidence vector.
    States, prior_probs, transition_probs, and emission_probs will now contain
    all the words from part_2_a.
    Evidence vector is a list of tuples where the first element of each tuple is the right
    hand coordinate and the second element is the right thumb coordinate.
    """
    # TODO: complete this function.͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄁͏󠄄͏󠄀
    raise NotImplementedError()

    sequence = []
    probability = 0.0

    return sequence, probability

########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄁͏󠄄͏󠄀
##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄁͏󠄄͏󠄀
################ END OF LOCAL TEST CODE SECTION ######################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄁͏󠄄͏󠄀

def return_your_name():
    """Return your name
    """
    # TODO: finish this͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄁͏󠄄͏󠄀

    return "Alexis Wilmot"